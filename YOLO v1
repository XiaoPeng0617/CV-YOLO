YOLO的设计实现了端到端训练、实时速度与高平均精度的平衡。  
系统将输入图像划分为S×S个网格。若物体中心落入某个网格单元，则该单元负责检测该物体。通常为7*7=49个单元格；groundtruth的中心落在那个单元格，就由那个单元格负责这个物体的检测即预测框的拟合整理。  
每个网格单元预测B（通常为2）个边界框及这些框的置信度。置信度反映模型对框内存在物体的信心以及预测框的准确性。正式定义为： 若单元内无物体，置信度应为零即C=0；否则，置信度应等于预测框与真实框的交并比（IOU在0-1之间）。  
每个边界框包含5个预测值：x, y, w, h和置信度c。 (x, y)坐标表示框中心相对于网格单元的边界位置，宽度w和高度h相对于整张图像预测。置信度表示预测框与真实框的IOU。  
每个网格单元还预测C（在版本1中为20）个条件类别概率Pr(Class i | Object),这些概率以网格单元包含物体为条件。无论B的数量如何，每个网格单元仅预测一组类别概率（20个类别概率中最高者）。测试时，我们将条件类别概率与各框置信度相乘：即类别概率与交并比的积为最终得分,得到每个框的类别特异性置信度。这些分数同时编码了该类别出现在框中的概率以及预测框与物体的匹配程度。
我们的系统将检测建模为回归问题。它将图像划分为 S ×S 网格，并针对每个网格单元格预测 B 边界框、这些框的置信度和 C 类概率。这些预测被编码为 S ×S×（B×5+C）的张量。
